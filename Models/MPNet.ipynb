{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "OLID MPNet Github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHijuspuuMkO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u6oSdNWHhpm"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N_7mKSDF2X0"
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRAL3V1w2w_"
      },
      "source": [
        "pip install plotly==4.5.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1BgltZfpfIb"
      },
      "source": [
        "!pip install transformers==4.2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR494XZ0FZ5h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjOCTC2LFZ5p"
      },
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\", \n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\", \n",
        "    \n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "    \n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "    \n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBrkiHZsFZ5v"
      },
      "source": [
        "def print_text(texts,i,j):\n",
        "    for u in range(i,j):\n",
        "        print(texts[u])\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2SiOlMFZ51"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/offenseval/olid-training-v1.0.tsv',delimiter='\\t',encoding='utf-8')\n",
        "print(list(df.columns.values)) #file header\n",
        "print(df.head(5)) #last N rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5uO1nfcyhw7"
      },
      "source": [
        "df.replace(np.NaN, 'NA', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDSHL-Uz13Aj"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEVYS5LfFZ57"
      },
      "source": [
        "text_array = df[\"tweet\"]\n",
        "labels = df[\"subtask_a\"]\n",
        "labels_target = df[\"subtask_b\"]\n",
        "print(len(text_array))\n",
        "print_text(text_array,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJRyIwRiTEi"
      },
      "source": [
        "original = text_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbgC7u_4jIO7"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvsUCosR5ck9"
      },
      "source": [
        "df_test_labels_b = pd.read_csv('/content/drive/My Drive/offenseval/labels-levelb.csv', header=None)\n",
        "print(len(df_test_labels_b))\n",
        "lol = df_test_labels_b[1]\n",
        "print(Counter(lol))\n",
        "df_test_labels_b.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6FcNLp8QzI"
      },
      "source": [
        "labels_target_test = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkBXvuXFZ6B"
      },
      "source": [
        "df_test_text = pd.read_csv('/content/drive/My Drive/offenseval/testset-levela.tsv',delimiter='\\t',encoding='utf-8')\n",
        "print(list(df_test_text.columns.values)) #file header\n",
        "print(df_test_text.head(5)) #first N rows\n",
        "\n",
        "df_test_labels = pd.read_csv('/content/drive/My Drive/offenseval/labels-levela.csv', header=None)\n",
        "print(list(df_test_labels.columns.values))\n",
        "print(df_test_labels.head(5))\n",
        "\n",
        "count = 0\n",
        "j = 0\n",
        "for i in range(0,len(df_test_text[\"id\"])):\n",
        "    if df_test_labels[1][i] == \"OFF\":\n",
        "        if df_test_labels[0][i] == df_test_labels_b[0][j]:\n",
        "            labels_target_test.append(df_test_labels_b[1][j])\n",
        "            j = j + 1\n",
        "    else:\n",
        "        labels_target_test.append(\"NA\")\n",
        "\n",
        "print(len(df_test_text[\"id\"]))        \n",
        "print(count)\n",
        "\n",
        "text_array_test = df_test_text[\"tweet\"]\n",
        "labels_test = df_test_labels[1]\n",
        "print(\"Checking length of validation set\")\n",
        "print(len(text_array_test),len(labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6jRCqVmQX4J"
      },
      "source": [
        "original_test = text_array_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bSNIGHn7ZNl"
      },
      "source": [
        "Counter(labels_target_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOC5ONKFZ6I"
      },
      "source": [
        "#removing website names\n",
        "def remove_website(text):\n",
        "    return \" \".join([word if re.search(\"r'https?://\\S+|www\\.\\S+'|((?i).com$|.co|.net)\",word)==None else \"\" for word in text.split(\" \") ])\n",
        "\n",
        "# Training set \n",
        "text_array = text_array.apply(lambda text: remove_website(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set \n",
        "text_array_test = text_array_test.apply(lambda text: remove_website(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKBHJaEkFZ6N"
      },
      "source": [
        "# Functions for chat word conversion\n",
        "f = open(\"/content/drive/My Drive/offenseval/slang.txt\", \"r\")\n",
        "chat_words_str = f.read()\n",
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8bYKRrNFZ6R"
      },
      "source": [
        "# Chat word conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array,0,10)\n",
        "print_text(original,0,10)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9YMXntG4p_"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/offenseval\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAVp4vfVFZ6W"
      },
      "source": [
        "#Function for emoticon conversion\n",
        "from emoticons import EMOTICONS\n",
        "\n",
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "        text = re.sub(u'('+emot+')', \" \".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#testing the emoticon function\n",
        "text = \"Hello :-) :-)\"\n",
        "text = convert_emoticons(text)\n",
        "print(text + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkDKvx9FZ6c"
      },
      "source": [
        "# Emoticon conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19UZfUjlFZ6h"
      },
      "source": [
        "# FUnction for removal of emoji\n",
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(\"_|-\",\" \",text)\n",
        "    return text\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn8WX-8FHbjC"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZITistjFZ6m"
      },
      "source": [
        "# Ekphrasis pipe for text pre-processing\n",
        "def ekphrasis_pipe(sentence):\n",
        "    cleaned_sentence = \" \".join(text_processor.pre_process_doc(sentence))\n",
        "    return cleaned_sentence\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Training set completed.......\")\n",
        "#Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Test set completed.......\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LXWqIKFZ6q"
      },
      "source": [
        "print_text(text_array,0,10)\n",
        "print(\"************************************************************************\")\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WO_7JIFZ6v"
      },
      "source": [
        "# Removing unnecessary punctuations\n",
        "PUNCT_TO_REMOVE = \"\\\"$%&'()+,-./;=[\\]^_`{|}~\"\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"********************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmxE8_s1Bbk"
      },
      "source": [
        "# print_text(text_array,3550,3555)\n",
        "print_text(original,9540,9555)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsNw3V7MFZ62"
      },
      "source": [
        "# Finding length of longest array\n",
        "maxLen = len(max(text_array,key = lambda text: len(text.split(\" \"))).split(\" \"))\n",
        "print(maxLen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlK2jraFZ68"
      },
      "source": [
        "u = lambda text: len(text.split(\" \"))\n",
        "sentence_lengths = []\n",
        "for x in text_array:\n",
        "    sentence_lengths.append(u(x))\n",
        "print(sorted(sentence_lengths)[-100:])\n",
        "print(len(sentence_lengths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q94LkYyFZ7A"
      },
      "source": [
        "<h2>Text pre-processing complete</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6iCqNnyFZ7X"
      },
      "source": [
        "# Count of each label in dataset\n",
        "from collections import Counter\n",
        "\n",
        "# Printing training set counts for analysis\n",
        "print(\"Elements: \",set(labels))\n",
        "print(\"Length: \",len(labels))\n",
        "print(Counter(labels))\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Printing validation set counts for analysis\n",
        "print(\"Elements: \",set(labels_test))\n",
        "print(\"Length: \",len(labels_test))\n",
        "print(Counter(labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "005HnK3xFZ7b"
      },
      "source": [
        "Y = []\n",
        "Y_test = []\n",
        "\n",
        "# Training set    \n",
        "for i in range(0,len(labels)):\n",
        "    if(labels[i] == \"OFF\"):\n",
        "        Y.append(0)\n",
        "    if(labels[i] == \"NOT\"):\n",
        "        Y.append(1)\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_test)):\n",
        "    if(labels_test[i] == \"OFF\"):\n",
        "        Y_test.append(0)\n",
        "    if(labels_test[i] == \"NOT\"):\n",
        "        Y_test.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOgKNrEBqXs"
      },
      "source": [
        "Y_target = []\n",
        "Y_target_test = []\n",
        "\n",
        "# Training set    \n",
        "for i in range(0,len(labels_target)):\n",
        "    if(labels_target[i] == \"NA\"):\n",
        "        Y_target.append(0)\n",
        "    if(labels_target[i] == \"TIN\"):\n",
        "        Y_target.append(1)\n",
        "    if(labels_target[i] == \"UNT\"):\n",
        "        Y_target.append(2)\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_target_test)):\n",
        "    if(labels_target_test[i] == \"NA\"):\n",
        "        Y_target_test.append(0)\n",
        "    if(labels_target_test[i] == \"TIN\"):\n",
        "        Y_target_test.append(1)\n",
        "    if(labels_target_test[i] == \"UNT\"):\n",
        "        Y_target_test.append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXy6Wxh2FZ7f"
      },
      "source": [
        "# Testing the conversion into integers\n",
        "for i in range(200,210):\n",
        "    print(text_array_test[i])\n",
        "    print(labels_test[i],Y_test[i])\n",
        "    print(labels_target_test[i],Y_target_test[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-95uJgsFZ7k"
      },
      "source": [
        "# Verifying train set \n",
        "X = np.asarray(list(text_array))\n",
        "Y = np.asarray(list(Y))\n",
        "Y_target = np.asarray(list(Y_target))\n",
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(type(Y_target))\n",
        "print(np.shape(X),np.shape(Y),np.shape(Y_target))\n",
        "\n",
        "# Verifying validation set\n",
        "X_test = np.asarray(list(text_array_test))\n",
        "Y_test = np.asarray(list(Y_test))\n",
        "Y_target_test = np.asarray(list(Y_target_test))\n",
        "print(type(X_test))\n",
        "print(type(Y_test))\n",
        "print(type(Y_target_test))\n",
        "print(np.shape(X_test),np.shape(Y_test),np.shape(Y_target_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se9u5rOU4DTf"
      },
      "source": [
        "print(Counter(Y))\n",
        "print(Counter(Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRqxpkqDnRrY"
      },
      "source": [
        "print(X_test[0])\n",
        "print(Y_test[0])\n",
        "print(labels_test[0])\n",
        "print(Y_target_test[0])\n",
        "print(labels_target_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZvFBMRRFZ7p"
      },
      "source": [
        "<h2>Shuffling training and validation data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9P3ZmhZFZ7r"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-U6ElWFZ7y"
      },
      "source": [
        "print(Counter(labels))\n",
        "print(Counter(labels_test))\n",
        "print(Counter(labels_target))\n",
        "print(Counter(labels_target_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQXXOb-FZ73"
      },
      "source": [
        "# Converting to one hot vectors\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)] #u[Y] helps to index each element of Y index at u. U here is a class array\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydeObXQFZ77"
      },
      "source": [
        "Y_oh_train = convert_to_one_hot(np.array(Y), C = 2)\n",
        "Y_oh_test = convert_to_one_hot(np.array(Y_test), C = 2)\n",
        "\n",
        "Y_oh_target_train = convert_to_one_hot(np.array(Y_target), C = 3)\n",
        "Y_oh_target_test = convert_to_one_hot(np.array(Y_target_test), C = 3)\n",
        "print(np.shape(Y_oh_train))\n",
        "print(np.shape(Y_oh_target_test))\n",
        "index = 0\n",
        "print(labels[index], Y[index], \"is converted into one hot\", Y_oh_train[index])\n",
        "print(labels_target[index], Y_target[index], \"is converted into one hot\", Y_oh_target_train[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk9YydcsFZ8C"
      },
      "source": [
        "<h2>Model using MPNet</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Lxn5eGvDAE"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w35qjBz-vEo3"
      },
      "source": [
        "from transformers import RobertaTokenizerFast, TFRobertaModel, TFBertModel, BertTokenizerFast, ElectraTokenizerFast, TFElectraModel, AlbertTokenizerFast, TFAlbertModel, XLNetTokenizerFast, TFXLNetModel, MPNetTokenizerFast, TFMPNetModel\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import RepeatVector, Concatenate, Dense, Activation, Dot, BatchNormalization, Dropout\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97gRRE9y383"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSTFXg6DYo8O"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Za2kQSGvVWI"
      },
      "source": [
        "tokenizer = MPNetTokenizerFast.from_pretrained('microsoft/mpnet-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_GaDaavdNk"
      },
      "source": [
        "X = list(X)\n",
        "X_test = list(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vEqLJDzNnE"
      },
      "source": [
        "model_train_x, model_val_x, Y_train, Y_val = train_test_split(X, Y, test_size=0.05, random_state=44)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2tYBEpvdJo"
      },
      "source": [
        "train_encodings = tokenizer(model_train_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "val_encodings = tokenizer(model_val_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "test_encodings = tokenizer(X_test, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE2O9UySazhE"
      },
      "source": [
        "cluster_encodings = tokenizer(X, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0VMHbInvcVi"
      },
      "source": [
        "print(np.shape(train_encodings[\"input_ids\"]))\n",
        "print(np.shape(val_encodings[\"input_ids\"]))\n",
        "print(np.shape(test_encodings[\"input_ids\"]))\n",
        "print(np.shape(cluster_encodings[\"input_ids\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYs7gYzsvcOa"
      },
      "source": [
        "print(train_encodings[\"input_ids\"][0])\n",
        "print(\"***************************************************************************\")\n",
        "print(val_encodings[\"input_ids\"][0])\n",
        "print(\"***************************************************************************\")\n",
        "print(test_encodings[\"input_ids\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdKykEUBmu5M"
      },
      "source": [
        "<h3> Subtask A</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRJHpbxaFZ86"
      },
      "source": [
        "def Offense_classifier(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the input,(max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 100-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (13 million words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "    model = TFMPNetModel.from_pretrained('microsoft/mpnet-base')\n",
        "    layer = model.layers[0]\n",
        "\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    inputs = keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = keras.Input(shape=input_shape, dtype='int32')\n",
        "    \n",
        "    embeddings = layer([inputs, input_masks])[0][:,0,:]\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(embeddings)\n",
        "    \n",
        "    # Add dropout with a probability of 0.1\n",
        "    X = Dropout(0.1)(X)\n",
        "    \n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(3,activation='elu',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(X)\n",
        "\n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "    \n",
        "    # Add a sigmoid activation\n",
        "    X = Activation('sigmoid')(X)\n",
        "    \n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = keras.Model(inputs=[inputs,input_masks], outputs=[X])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoCY8kjG0DC5"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLnuscUj0IjO"
      },
      "source": [
        "class EvaluationMetric(keras.callbacks.Callback):   \n",
        "    \n",
        "    def __init__(self, trial_encodings, trial_masks, Y_test):\n",
        "        super(EvaluationMetric, self).__init__()\n",
        "        self.trial_encodings = trial_encodings\n",
        "        self.trial_masks = trial_masks\n",
        "        self.Y_test = Y_test\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"\\nTraining...\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"\\nEvaluating...\")\n",
        "        trial_prediction = self.model.predict([self.trial_encodings,self.trial_masks])\n",
        "        \n",
        "        pred = []\n",
        "        for i in range(0,len(self.Y_test)):\n",
        "            num = trial_prediction[i]\n",
        "            if(num > 0.5):\n",
        "              num = 1\n",
        "            else:\n",
        "              num = 0\n",
        "            pred.append(num)\n",
        "        \n",
        "        from sklearn.metrics import classification_report\n",
        "        print(classification_report(Y_test, pred, digits=3))\n",
        "        \n",
        "evaluation_metric = EvaluationMetric(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOUVfDy0IYr"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = Offense_classifier((100,))\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=2e-5)\n",
        "    loss_fun = [\n",
        "          tf.keras.losses.BinaryCrossentropy()\n",
        "    ]\n",
        "    metric = ['acc']\n",
        "    model.compile(optimizer=optimizer, loss=loss_fun, metrics=metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQdfWk222Act"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM223PhsK5Ir"
      },
      "source": [
        "neg, pos = np.bincount(Y)\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtur56mLoep"
      },
      "source": [
        "class_weight = {}\n",
        "maxi = max(neg, pos)\n",
        "weight_for_0 = (maxi / (maxi + neg)) \n",
        "weight_for_1 = (maxi / (maxi + pos))\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mEBrm9NFZ9W"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath='/content/olid_mpnet_val_change.{epoch:03d}.h5',\n",
        "                                 monitor='val_acc',\n",
        "                                 verbose=1,\n",
        "                                 save_weights_only=True,\n",
        "                                 period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5OEmpHyzDQ-"
      },
      "source": [
        "print(Counter(Y))\n",
        "print(Counter(Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Ejap9-cMoj"
      },
      "source": [
        "print(Counter(Y_train))\n",
        "print(Counter(Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Otd9w3JbVbq"
      },
      "source": [
        "print(len(train_encodings[\"input_ids\"]),len(val_encodings[\"input_ids\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2YmBdxovz2N"
      },
      "source": [
        "# Using val set of 0.05\n",
        "history = model.fit(\n",
        "    x = [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"]],\n",
        "    y = Y_train,\n",
        "    validation_data = ([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]],Y_val),\n",
        "    callbacks = [evaluation_metric, checkpoint],\n",
        "    batch_size = 64,\n",
        "    shuffle=True,\n",
        "    epochs=6,\n",
        "    class_weight = class_weight\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C9gJOp-3pK6"
      },
      "source": [
        "<h4>Training Curves</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EzL7l_M1HXA"
      },
      "source": [
        "history = history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhp7jUyPWVf5"
      },
      "source": [
        "# model.load_weights(\"/content/drive/MyDrive/OLID Transformer weights/olid_mpnet(0.05).002.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ06iVLk6Y4V"
      },
      "source": [
        "# model.save_weights(\"/content/drive/MyDrive/OLID Transformer weights/olid_mpnet.003.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlcmHgY2QL8u"
      },
      "source": [
        "<h4>Test Set Statistics</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlkXuAvTFZ9z"
      },
      "source": [
        "answer = model.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAh-EgxOS4I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ce0b2c-8cc8-4c49-98cf-61609dd4ed2b"
      },
      "source": [
        "pred = []\n",
        "sample = df_test_text[\"tweet\"]\n",
        "count = 0\n",
        "for i in range(0,len(X_test)):\n",
        "\n",
        "    num = answer[i]\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVOLWrFkhnv"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeT_iT6HvKF2"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YRvE7emtL9M"
      },
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.set(font_scale=1.75)\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.viridis,fmt='d', xticklabels=[\"Offensive\",\"Not Offensive\"], yticklabels=[\"Offensive\",\"Not Offensive\"],annot_kws={\"size\": 15})\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jj5ISVyu6Mc"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hznYcG3LtVhx"
      },
      "source": [
        "f1_score(Y_test, pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9Q-xbecQRM"
      },
      "source": [
        "print(classification_report(Y_test, pred, target_names=[\"offensive\", \"not offensive\"], digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVY5iNvkS5aB"
      },
      "source": [
        "<h3>Train set analysis</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nudw40bYS5Co"
      },
      "source": [
        "answer_train = model.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8p8hcOTIoE"
      },
      "source": [
        "pred = []\n",
        "sample = original\n",
        "count = 0\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]\n",
        "    lol = num\n",
        "    if(num > 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)\n",
        "    if(num != Y[i] and Y[i] == 0 and lol >=0.8):\n",
        "        print(answer_train[i])\n",
        "        print(\"Original label: \",labels[i])\n",
        "        print(\"Without pre-processing: \",sample[i])\n",
        "        print(\"With pre-processing: \",X[i])\n",
        "        lol = \"\"\n",
        "        count += 1\n",
        "\n",
        "        if(num == 0):\n",
        "            lol = \"Offensive\"\n",
        "        if(num == 1):\n",
        "            lol = \"Not Offensive\"\n",
        "        print(\"Predicted: \" + lol)\n",
        "        print()\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDHYC0jVktN0"
      },
      "source": [
        "<h3>Training examination</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_JXxlJUIE4I"
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx8jYvYCng6n"
      },
      "source": [
        "# 3 neuron output\n",
        "model.layers[-6].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJS7gXgJFCCa"
      },
      "source": [
        "cluster_dense_3 = keras.Model(inputs=model.input, outputs=model.layers[-6].output)\n",
        "with strategy.scope():\n",
        "    cluster_3 = cluster_dense_3.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn_QbPYsk9es"
      },
      "source": [
        "pred_train = []\n",
        "temp = 0\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]\n",
        "\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred_train.append(num)\n",
        "\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeHnrAsbpq0b"
      },
      "source": [
        "flag = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_.append(cluster_3[i][2])\n",
        "    y_.append(cluster_3[i][1])\n",
        "    z_.append(cluster_3[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aodbtdXNvHhz"
      },
      "source": [
        "Counter(flag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5W6RP9YlCnx"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y, predictions=pred_train)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xr1InDUIS7_"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if flag[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if flag[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if flag[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'x':x_, 'y':y_, 'z':z_, 'Labels':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='x', y='y', z='z', color='Labels')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.7,\n",
        "        'colorscale' : 'Oryel',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 750, height = 500)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdnHRRJ_rTr6"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvADyeWtkyCa"
      },
      "source": [
        "<h3>Traning examination end</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUPHuPieZk7"
      },
      "source": [
        "<h1>CLUSTERING</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCoFfK-90oxq"
      },
      "source": [
        "<h3>MPNet PLM layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZTddCJb0oJD"
      },
      "source": [
        "model.layers[-8].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk32a2tk0oFC"
      },
      "source": [
        "cluster_bert = keras.Model(inputs=model.input, outputs=model.layers[-8].output)\n",
        "with strategy.scope():\n",
        "    cl_bert = cluster_bert.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7-V0NqLGqd"
      },
      "source": [
        "len(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVtIKDOf0oBM"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCAnjXj79OhP"
      },
      "source": [
        "<p>k-means PLM MPNet</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgg7vxiCfX9C"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDh5fAcH0n9H"
      },
      "source": [
        "kmeans_bert = KMeans(n_clusters=3, random_state=44).fit(cl_bert)\n",
        "y_kmeans_bert = kmeans_bert.predict(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-RuV1hD0n4w"
      },
      "source": [
        "Counter(y_kmeans_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB90wC8s0n0Y"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n1QV3RZ0nvi"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 1 and y_kmeans_bert[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkPj1SQh2xwF"
      },
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(y_kmeans_bert[i] == 0):\n",
        "      y_kmeans_bert[i] = 2\n",
        "    elif(y_kmeans_bert[i] == 1):\n",
        "      y_kmeans_bert[i] = 1\n",
        "    else:\n",
        "      y_kmeans_bert[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veXnzAlUMw7R"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "        \n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yshzveBsM4Fm"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUCI6rBn2xka"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=y_kmeans_bert)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctpCXXhOo8Cf"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, y_kmeans_bert, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCwmwVNe2xVm"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-88zP4sK2xHi"
      },
      "source": [
        "centers_bert = kmeans_bert.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0TowJm0nex"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    off = cosine(cl_bert[i], centers_bert[2])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRWKQ8RI4Ral"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    noff = cosine(cl_bert[i], centers_bert[1])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKo_zWN74RWB"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    neu = cosine(cl_bert[i], centers_bert[0])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xakK3QUgNM8G"
      },
      "source": [
        "<h5>k-means PLM Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6gKpMTzZYLu"
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgdXokQMXnFF"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    },\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIzJQ91XrYFN"
      },
      "source": [
        "pred_kmpnet = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_noff[i]):\n",
        "        pred_kmpnet.append(0)\n",
        "    else:\n",
        "        pred_kmpnet.append(1)\n",
        "print(classification_report(Y_test, pred_kmpnet, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-V1ldlzrX-2"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred_kmpnet)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQoSZi6exAc"
      },
      "source": [
        "<p> GMM model PLM</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ty06IQHewe7"
      },
      "source": [
        "from sklearn.mixture import GaussianMixture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4PkC0bPfAB9"
      },
      "source": [
        "gmm_bert = GaussianMixture(n_components=3, random_state = 44).fit(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r87Jsg3oe_UH"
      },
      "source": [
        "mean_bert = gmm_bert.means_\n",
        "cov_bert = gmm_bert.covariances_\n",
        "print(np.shape(mean_bert))\n",
        "print(np.shape(cov_bert))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KakHZ0KYe_QM"
      },
      "source": [
        "labels_bert = gmm_bert.predict(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWqCpdnbKLPt"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3sXMOuJKefR"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqRelHjIhQhq"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 2 and labels_bert[i] == 0:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvseXiiahQD0"
      },
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(labels_bert[i] == 0):\n",
        "      labels_bert[i] = 2\n",
        "    elif(labels_bert[i] == 1):\n",
        "      labels_bert[i] = 1\n",
        "    else:\n",
        "      labels_bert[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuN6XZY9Kuys"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWmgNWKahjLk"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=labels_bert)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3od2lBfD3Z41"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, labels_bert, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ZEaAn-Ftq8"
      },
      "source": [
        "prob_bert = gmm_bert.predict_proba(cl_bert)\n",
        "prob_bert = prob_bert.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq43uk25N8-Y"
      },
      "source": [
        "<h5>GMM PLM plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fITkqpNDaNtR"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_bert[2], 'SVNS Non Offensive':prob_bert[1], 'SVNS Neutral':prob_bert[0], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Non Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.8,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYTb160z1N4"
      },
      "source": [
        "<h3>Dense 3 layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsnmLYS8IKwY"
      },
      "source": [
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gdI2YnUypsL"
      },
      "source": [
        "cl_norm = normalize(cluster_3, norm='l2', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2leCxqUczL9r"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][0])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_3.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etG96swj-ILL"
      },
      "source": [
        "<p>k-means Dense 3</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF5bqOYoM9nb"
      },
      "source": [
        "kmeans_3 = KMeans(n_clusters=3, random_state=4).fit(cl_norm)\n",
        "y_kmeans_3 = kmeans_3.predict(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ugjvzrPOhp"
      },
      "source": [
        "Counter(y_kmeans_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGNkI4XGSJeq"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3QrGYwJPXkh"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_3)):\n",
        "      if flag_3[i] == 0 and y_kmeans_3[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2TyIP3PYcM"
      },
      "source": [
        "for i in range(0,len(flag_3)):\n",
        "    if(y_kmeans_3[i] == 0):\n",
        "      y_kmeans_3[i] = 1\n",
        "    elif(y_kmeans_3[i] == 1):\n",
        "      y_kmeans_3[i] = 0\n",
        "    else:\n",
        "      y_kmeans_3[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKSpqPoiPeSG"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_3.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XZjQHoow4J"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YMxovgxcgLU"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_3, predictions=y_kmeans_3)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGH7CdfRdFl"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_3, y_kmeans_3, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3angcCcHEw5"
      },
      "source": [
        "<p>Transition phase</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66dJKDnVdvPV"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_3[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_3[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_3[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVkZLf0wHLol"
      },
      "source": [
        "<p>Original predictions</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiNW3HXMfO-i"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7d1l_ubROD6"
      },
      "source": [
        "<h4>End of transition capture</h4> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQHolZXSuzK2"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSkLQp_7uy6B"
      },
      "source": [
        "centers_3 = kmeans_3.cluster_centers_\n",
        "print(centers_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USgTEi4ruyos"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    off = cosine(cl_norm[i], centers_3[1])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Hxo-QLvt1U"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    noff = cosine(cl_norm[i], centers_3[0])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF5b8CvBvvGo"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    neu = cosine(cl_norm[i], centers_3[2])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZad5lE_Om-6"
      },
      "source": [
        "<h5>k-means Dense 3 Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDi2Kr1EdDoU"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_3[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_3[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_3[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mtZLIk-tZg7"
      },
      "source": [
        "pred_dmpnet = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_noff[i]):\n",
        "        pred_dmpnet.append(0)\n",
        "    else:\n",
        "        pred_dmpnet.append(1)\n",
        "print(classification_report(Y_test, pred_dmpnet, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noeQOvnUtZS9"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred_dmpnet)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UxQLMFmyX_G"
      },
      "source": [
        "<p> GMM model Dense 3</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3TUE0zyXEr"
      },
      "source": [
        "gmm_3 = GaussianMixture(n_components=3, random_state = 44).fit(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebI2i-bryW7A"
      },
      "source": [
        "mean_norm = gmm_3.means_\n",
        "cov_norm = gmm_3.covariances_\n",
        "print(np.shape(mean_norm))\n",
        "print(np.shape(cov_norm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G4NEJI2yWyI"
      },
      "source": [
        "labels_norm = gmm_3.predict(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NR_8RmWNdY"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_3.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-hLHbbSa8R"
      },
      "source": [
        "Counter(labels_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFJc8jcvWRuc"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVx299gsyWqC"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_3)):\n",
        "      if flag_3[i] == 1 and labels_norm[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwj7FBuSzEGw"
      },
      "source": [
        "for i in range(0,len(flag_3)):\n",
        "    if(labels_norm[i] == 0):\n",
        "      labels_norm[i] = 0\n",
        "    elif(labels_norm[i] == 1):\n",
        "      labels_norm[i] = 1\n",
        "    else:\n",
        "      labels_norm[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPH-CLYbWtmD"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_3.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLy6RirzECt"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_3, predictions=labels_norm)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K04A25tK40Y8"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_3, labels_norm, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzerzBvA5yh0"
      },
      "source": [
        "prob_norm = gmm_3.predict_proba(cl_norm)\n",
        "prob_norm = prob_norm.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PFUDsrmPLb8"
      },
      "source": [
        "<h5> GMM Dense 3 Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ata8zfmjg6lj"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_norm[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_norm[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_norm[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_norm[0], 'SVNS Not Offensive':prob_norm[1], 'SVNS Neutral':prob_norm[2], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.5,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoSh2HkVM-FR"
      },
      "source": [
        "<h3>Dense 3 layer end</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KReciSt2OQ"
      },
      "source": [
        "<h3>Batch Norm layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy39KUfk4YCu"
      },
      "source": [
        "model.layers[-4].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2ar9of0Duo"
      },
      "source": [
        "cluster_32 = keras.Model(inputs=model.input, outputs=model.layers[-4].output)\n",
        "with strategy.scope():\n",
        "    cl_32 = cluster_32.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge2aGeyg4jqM"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_32.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IJQId7D-18i"
      },
      "source": [
        "<p>k-means BatchNorm layer</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nv_fX296vdI"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans_32 = KMeans(n_clusters=3, random_state=44).fit(cl_32)\n",
        "y_kmeans_32 = kmeans_32.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkhMcNKJejg"
      },
      "source": [
        "Counter(y_kmeans_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EakhhsbKfjfX"
      },
      "source": [
        "Counter(flag_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnXxczDPWVlZ"
      },
      "source": [
        "# 2 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 0 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(y_kmeans_32)):\n",
        "      if flag_32[i] == 1 and y_kmeans_32[i] == 0:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPxtiMV_trW"
      },
      "source": [
        "for i in range(0,len(y_kmeans_32)):\n",
        "    if(y_kmeans_32[i] == 0):\n",
        "      y_kmeans_32[i] = 1\n",
        "    elif(y_kmeans_32[i] == 1):\n",
        "      y_kmeans_32[i] = 0\n",
        "    else:\n",
        "      y_kmeans_32[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toe6CE1ilYGj"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_32.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4X5_bGfAwo"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_32, predictions=y_kmeans_32)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpGwKo4jqQPO"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_32, y_kmeans_32, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBWvBFEyyoF"
      },
      "source": [
        "centers_32 = kmeans_32.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sisL0IvdrTP"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y)):\n",
        "    off = cosine(cl_32[i], centers_32[1])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqDGo4o8k8Ph"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y)):\n",
        "    noff = cosine(cl_32[i], centers_32[0])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7abIoiRk8CH"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y)):\n",
        "    neu = cosine(cl_32[i], centers_32[2])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUTj_kZ3-9zg"
      },
      "source": [
        "<p>k-means BatchNorm Plot</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbsHcP9Jkjnf"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(svns_neu)):\n",
        "    if y_kmeans_32[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_32[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_32[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQgRmVhUtoQC"
      },
      "source": [
        "pred_BNmpnet = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_noff[i]):\n",
        "        pred_BNmpnet.append(0)\n",
        "    else:\n",
        "        pred_BNmpnet.append(1)\n",
        "print(classification_report(Y_test, pred_BNmpnet, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GluXSZUytoDm"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=lolol)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2xr2iN58eQe"
      },
      "source": [
        "<p> GMM Model BatchNorm</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnfQ9GrSm2Hh"
      },
      "source": [
        "gmm_32 = GaussianMixture(n_components=3, random_state = 44).fit(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN1DnstL8hfC"
      },
      "source": [
        "mean_32 = gmm_32.means_\n",
        "cov_32 = gmm_32.covariances_\n",
        "print(np.shape(mean_32))\n",
        "print(np.shape(cov_32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCCf6p2W8hbh"
      },
      "source": [
        "labels_32 = gmm_32.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq5znocnV2VF"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_32.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5AgvLFl-4On"
      },
      "source": [
        "Counter(flag_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A7HVs_P8hX2"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_32)):\n",
        "      if flag_32[i] == 0 and labels_32[i] == 0:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjsJFtnd8hT5"
      },
      "source": [
        "for i in range(0,len(flag_32)):\n",
        "    if(labels_32[i] == 0):\n",
        "      labels_32[i] = 0\n",
        "    elif(labels_32[i] == 1):\n",
        "      labels_32[i] = 1\n",
        "    else:\n",
        "      labels_32[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFMHwFz5YY8Q"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_32.append(2)\n",
        "    \n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CV6mSbW8hP2"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_32, predictions=labels_32)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU2xjTjG5i6o"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_32, labels_32, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8LxWjbDpkG"
      },
      "source": [
        "prob_32 = gmm_32.predict_proba(cl_32)\n",
        "prob_32 = prob_32.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnTb3W99_RWV"
      },
      "source": [
        "<p>GMM BatchNorm Plot</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Nfvvi1lTsO"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_32[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_32[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_32[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_32[0], 'SVNS Not Offensive':prob_32[1], 'SVNS Neutral':prob_32[2], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.5,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}